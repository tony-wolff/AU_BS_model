{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from scipy import signal\n",
    "from scipy import interpolate\n",
    "from matplotlib import pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### AU BS lagMeasure\n",
    "this file created the AU26-JawOpen-lagMeasure.csv\n",
    "it compares blendshapes csv for each script from Miyawaki dataset and Action Unit.csv obtained with OpenFace and video in Miyawaki's folders\n",
    "the lag is computed with cross correlation and stored for each script of each participant in this lagMeasure.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_framerate(data) -> float:\n",
    "    '''\n",
    "    returns the framerate of timecode array that starts from 0\n",
    "    '''\n",
    "    n_seconds = np.sum(np.diff(data))\n",
    "    n_frames = data.shape[0]-1\n",
    "    framerate = n_frames / n_seconds\n",
    "    return framerate\n",
    "\n",
    "def low_pass_filter(csv_file: str, window_ms: int=100) -> pd.DataFrame:\n",
    "    '''\n",
    "    low pass filter the data to filter noise using a sliding windows of 100ms by default\n",
    "    outputs a new csv file\n",
    "    '''\n",
    "    window_size = int(window_ms*60/1000)\n",
    "    bs_df = pd.read_csv(csv_file, sep=', ')\n",
    "    #drop the frame columnm, as it is not useful anymore\n",
    "    rolling = bs_df.drop(\"frame\", axis=1).rolling(window_size).mean()\n",
    "    return rolling\n",
    "\n",
    "def cross_corr_with_savgol_filter(signal1, signal2, window_size: int) -> tuple[list[float], list[float]]:\n",
    "    '''\n",
    "    returns the correlation and the lags in a list\n",
    "    '''\n",
    "    #Before cross correlation, a savgol filter is applied to smooth high frequencies\n",
    "    y_au_filtered = signal.savgol_filter(signal1, window_size, 1)\n",
    "    y_bs_filtered = signal.savgol_filter(signal2.to_numpy().flatten(), window_size, 1)\n",
    "    correlation = signal.correlate(\n",
    "        y_au_filtered-np.mean(y_au_filtered), y_bs_filtered-np.mean(y_bs_filtered), mode=\"full\"\n",
    "    ) #substracting the mean makes computing more accurate\n",
    "    #The lag is the refers to how far the series are offset\n",
    "    lags = signal.correlation_lags(len(y_au_filtered), len(y_bs_filtered), mode=\"full\")\n",
    "    return [correlation, lags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41368707735d4253ada2fa62fce67dcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "604e0d031e524ac6a2c4cf5f97b2d399",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/420 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90b676a74f014e95be2c0cb9f59811d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/420 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df6231adf9c449a482bd0bed7246f765",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/420 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f537530f46fe4fbbb6edff75eb6275df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/420 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d72944dc8844475086d092d18876062b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/420 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ead5c3276e64669a99b18c04997234f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/420 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea6c8b514a794a2eac7c35c22e8f79a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/420 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41aecdbf4c6943158b3d618385c69efc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/420 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31406d4a1eff4bf292d96291b1ef5717",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/420 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Header [\n",
    "#     blendshape_scriptID,average_frame_rate_OF,average_frame_rate_ARKIT,\n",
    "#     n_frames_OF,n_frame_ARKIT,delay_ms,max_corr\n",
    "# ]\n",
    "#Title of the .csv : AU26-JawOpen-lagMeasure.csv\n",
    "\n",
    "path = \"C:/Users/Tony/Documents/TestData\"\n",
    "list_participants_id_path = [f.path for f in os.scandir(path) if f.is_dir() and \".\" not in f.name]\n",
    "#os.path.basename(list_participants_id_path[0])\n",
    "\n",
    "def find_corresponding_blendshape_csv(participants_id_path, filepath):\n",
    "    filename = os.path.basename(filepath)\n",
    "    path_to_bs_csv = participants_id_path+\"/csv_whole/individual\"\n",
    "    emotion_intensity = filename.split('!')[1]\n",
    "    emotion_number = filename.split('!')[2]\n",
    "    file = [f.path for f in os.scandir(path_to_bs_csv) if emotion_intensity in f.name and emotion_number in f.name]\n",
    "    return file[0]\n",
    "\n",
    "\n",
    "def compute_correlation_and_delay(y_au, y_bs, ws_low_pass_filter, ws_savgol_filter):\n",
    "    #Low pass filter of a windows size of 100\n",
    "    y1_tmp = y_au.rolling(ws_low_pass_filter).mean().dropna()\n",
    "    y2_tmp = y_bs.rolling(ws_low_pass_filter).mean().dropna()\n",
    "\n",
    "    y_au = y_au.rolling(ws_low_pass_filter).mean().fillna(np.mean(y1_tmp))\n",
    "    y_bs = y_bs.rolling(ws_low_pass_filter).mean().fillna(np.mean(y2_tmp))\n",
    "\n",
    "    #--Cross correlation--\n",
    "    correlation, lags = cross_corr_with_savgol_filter(y_au, y_bs, ws_savgol_filter)\n",
    "    #We get the lag at the peak of the correlation, when both signal correlate the best\n",
    "    lag = lags[np.argmax(abs(correlation))]\n",
    "    return [np.max(correlation), lag]\n",
    "\n",
    "def create_lag_measure_dataset(participants_id_path, au_name, bs_name):\n",
    "    columns = [\n",
    "        'participant_id', 'blendshape_scriptID','average_frame_rate_OF','average_frame_rate_ARKIT',\n",
    "        'n_frames_OF','n_frame_ARKIT','max_lag','delay_ms','max_corr'\n",
    "    ]\n",
    "    dataframe_res = pd.DataFrame(columns=columns)\n",
    "\n",
    "    for participant_path in tqdm(participants_id_path):\n",
    "        list_of_openface_csvs = [\n",
    "            f.path for f in os.scandir(participant_path) if f.is_file and f.name.endswith('.csv')\n",
    "        ]\n",
    "        participant_id = os.path.basename(participant_path)\n",
    "\n",
    "        for openface_csv in tqdm(list_of_openface_csvs):\n",
    "            blendshape_csv = find_corresponding_blendshape_csv(participant_path, openface_csv)\n",
    "            au_df = pd.read_csv(openface_csv, sep=\", \", engine ='python')\n",
    "            bs_df = pd.read_csv(blendshape_csv)\n",
    "            x_au = au_df[\"timestamp\"]\n",
    "            y_au = au_df[au_name]\n",
    "            x_bs = bs_df[\"Timecode\"]\n",
    "            y_bs = bs_df[bs_name]\n",
    "            x_bs = pd.to_datetime(x_bs, format=\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "            x_bs -= x_bs[0]\n",
    "            y_au/=5 # normalization between 0 and 1\n",
    "\n",
    "            framerate_au = compute_framerate(x_au)\n",
    "            framerate_bs = compute_framerate(x_bs.dt.total_seconds())\n",
    "            n_frames_au = x_au.shape[0]\n",
    "            n_frames_bs = x_bs.shape[0]\n",
    "            max_corr, max_lag = compute_correlation_and_delay(y_au, y_bs, 6, 4)\n",
    "            delay_ms = abs(max_lag)/framerate_bs\n",
    "            scriptId = os.path.basename(blendshape_csv).rsplit(\"_\", 1)[0]\n",
    "\n",
    "            dictionary = {\n",
    "                \"participant_id\":participant_id, \"blendshape_scriptID\": scriptId,\n",
    "                'average_frame_rate_OF': framerate_au, 'average_frame_rate_ARKIT': framerate_bs,\n",
    "                'n_frames_OF': n_frames_au, 'n_frame_ARKIT': n_frames_bs, 'max_lag': max_lag,\n",
    "                'delay_ms': delay_ms, 'max_corr': max_corr\n",
    "            }\n",
    "            dataframe_res = pd.concat(\n",
    "                [dataframe_res, pd.DataFrame.from_records([dictionary])], ignore_index=True\n",
    "            ) #append is deprecated, concat is now used\n",
    "    \n",
    "    dataframe_name = \"%s-%s-lagMeasure.csv\" % (au_name, bs_name)\n",
    "    dataframe_res.to_csv(\n",
    "        dataframe_name, index=False\n",
    "    ) #Index=False removes the unamed index column that is added by default\n",
    "    \n",
    "\n",
    "create_lag_measure_dataset(list_participants_id_path, \"AU26_r\", \"JawOpen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
