{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A notebook to compare videos of the avatar using different models for animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean ssim 97.32744856895044%\n",
      "mean psnr 41.894250215994646\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity\n",
    "\n",
    "video1 = cv2.VideoCapture('videos/low_9_gt.mkv')\n",
    "video2 = cv2.VideoCapture('videos/model0.1_low_9_pred.mkv')\n",
    "FHD = (1920, 1080)\n",
    "out_gt = cv2.VideoWriter('out_gt.mp4', -1, 60, FHD) #name, codec, framerate, resolution\n",
    "out_pred = cv2.VideoWriter('out_pred.mp4', -1, 60, FHD)\n",
    "diff_vid = cv2.VideoWriter('diff.mp4', -1, 60, FHD)\n",
    "diff_box_vid = cv2.VideoWriter('diff_box.mp4', -1, 60, FHD)\n",
    "mask_vid = cv2.VideoWriter('mask.mp4', -1, 60, FHD)\n",
    "filled_vid = cv2.VideoWriter('filled.mp4', -1, 60, FHD)\n",
    "\n",
    "psnr_array = []\n",
    "ssim_array = []\n",
    "\n",
    "def calculate_psnr(original, prediction):\n",
    "    mse = np.mean((original - prediction) ** 2)\n",
    "    max_pixel_value = 255.0\n",
    "    psnr = 20 * np.log10(max_pixel_value / np.sqrt(mse))\n",
    "    return psnr\n",
    "\n",
    "while(video1.isOpened()):\n",
    "    ret1, original = video1.read()\n",
    "    ret2, prediction = video2.read()\n",
    "\n",
    "    if not ret1 or not ret2:\n",
    "        break\n",
    "    \n",
    "    original_g = cv2.cvtColor(original, cv2.COLOR_BGR2GRAY)\n",
    "    prediction_g = cv2.cvtColor(prediction, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    #frame_diff = cv2.absdiff(original_g, prediction_g)\n",
    "    psnr = calculate_psnr(original, prediction)\n",
    "    (score, diff) = structural_similarity(original_g, prediction_g, full=True) #ssim between -1 et 1, can be represented as a %\n",
    "    diff = (diff * 255).astype(\"uint8\")\n",
    "    diff_box = cv2.merge([diff, diff, diff])\n",
    "\n",
    "    # Threshold the difference image, followed by finding contours to\n",
    "    # obtain the regions of the two input images that differ\n",
    "    thresh = cv2.threshold(diff, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "    contours = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = contours[0] if len(contours) == 2 else contours[1]\n",
    "\n",
    "    mask = np.zeros(original.shape, dtype='uint8')\n",
    "    filled_after = prediction.copy() #filled is the predicted frame where filled section are differences with the ground truth frame\n",
    "    \n",
    "    for c in contours:\n",
    "        area = cv2.contourArea(c)\n",
    "        if area > 40:\n",
    "            x,y,w,h = cv2.boundingRect(c)\n",
    "            cv2.rectangle(original, (x, y), (x + w, y + h), (36,255,12), 2)\n",
    "            cv2.rectangle(prediction, (x, y), (x + w, y + h), (36,255,12), 2)\n",
    "            cv2.rectangle(diff_box, (x, y), (x + w, y + h), (36,255,12), 2)\n",
    "            cv2.drawContours(mask, [c], 0, (255,255,255), -1)\n",
    "            cv2.drawContours(filled_after, [c], 0, (0,255,0), -1)\n",
    "\n",
    "    # cv2.imshow('original', original)\n",
    "    # cv2.imshow('prediction', prediction)\n",
    "    # cv2.imshow('diff', diff)\n",
    "    # cv2.imshow('diff_box', diff_box)\n",
    "    # cv2.imshow('mask', mask)\n",
    "    # cv2.imshow('filled after', filled_after)\n",
    "    out_gt.write(original)\n",
    "    out_pred.write(prediction)\n",
    "    diff_vid.write(diff)\n",
    "    diff_box_vid.write(diff_box)\n",
    "    mask_vid.write(mask)\n",
    "    filled_vid.write(filled_after)\n",
    "\n",
    "    psnr_array.append(psnr)\n",
    "    ssim_array.append(score*100)\n",
    "\n",
    "print(f\"mean ssim {np.mean(ssim_array)}%\")\n",
    "print(f\"mean psnr {np.mean(psnr_array)}\")\n",
    "video1.release()\n",
    "video2.release()\n",
    "out_gt.release()\n",
    "out_pred.release()\n",
    "diff_vid.release()\n",
    "diff_box_vid.release()\n",
    "mask_vid.release()\n",
    "filled_vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1666666716337204"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "#test how the padding affect the loss computation\n",
    "array = [1, 1, 1, 0, 0, 0]\n",
    "array2 = [1, 1, 0, 0, 0, 0]\n",
    "torch.nn.functional.mse_loss(torch.FloatTensor(array), torch.FloatTensor(array2)).item()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
